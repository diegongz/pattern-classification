{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a03df60-9bb8-4b89-9631-c13f39d56c98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tarea 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7167f-9bce-4c6d-b31d-72a93bf1cd1e",
   "metadata": {},
   "source": [
    "### Parte 1 NUTT DS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a92c34-f64c-4a0f-9774-4988323c4d07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48e0243-3a50-4fd0-b317-2aa9ae81c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#path of the file\n",
    "p= \"D:\\\\CIC\\\\CIP\\\\data_sets\\\\nutt\\\\Nutt.csv\"\n",
    "with open(p, newline='') as csvfile:\n",
    "    \n",
    "    # create a CSV reader object\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # create a list to hold the rows of the CSV file\n",
    "    df = []\n",
    "    \n",
    "    # loop through each row in the CSV file\n",
    "    for row in csvreader:\n",
    "        \n",
    "        # convert the row to a list of numbers\n",
    "        num_row = [float(x) for x in row]\n",
    "        \n",
    "        # add the num_row to the list of rows\n",
    "        df.append(num_row)\n",
    "        \n",
    "# print the 2D list\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a592738d-49a6-4107-81b4-5d7341dc9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_and_neg(df,class_pos,class_neg):\n",
    "    n = len(df[0])-1 #position of the class column\n",
    "    \n",
    "    df_pos = []\n",
    "    df_neg = []\n",
    "    \n",
    "    for x in df:\n",
    "        if x[n] == class_pos:\n",
    "            df_pos.append(x)\n",
    "        else:\n",
    "            df_neg.append(x)\n",
    "    \n",
    "    for row in df_pos:\n",
    "        row.pop()\n",
    "    \n",
    "    for row in df_neg:\n",
    "        row.pop()\n",
    "    \n",
    "    return df_pos,df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c500b58-00ec-400f-a830-5159bde27fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos,df_neg = pos_and_neg(df,1,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fd3400-4ef5-419a-b0d2-5d230f219174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation= df_neg+df_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbef2c2c-bfd5-4f9f-ab8c-e5c10f2a5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last index for the first class (positive) rows in df_validation\n",
    "n= len(df_neg)-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05399f4-2995-42ac-94e7-675b44b85494",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3c7a85-338c-43c7-af08-184a3f7e0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "\n",
    "#K-NN with Leave One Out Cross Validation\n",
    "def knn_LOOCV(k,df_validation,class_positive,class_negative,index_test,last_positive_index,TP,FN,FP,TN):\n",
    "    train_df = df_validation #dataset where the first patterns are all positive class and the second part are all negative class\n",
    "\n",
    "    pattern_index = index_test\n",
    "    test_df = df_validation[pattern_index]\n",
    "\n",
    "    n=last_positive_index\n",
    "    \n",
    "    if pattern_index<=n:\n",
    "        class_of_test_pattern = class_positive\n",
    "    else:\n",
    "        class_of_test_pattern = class_negative\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for i in range(len(train_df)):\n",
    "\n",
    "        dist = round(math.dist(test_df, train_df[i]),4)\n",
    "        \n",
    "\n",
    "        if i<=n:\n",
    "            distances.append([dist,i+1,class_positive]) #it need to be sum one because of the python numeration\n",
    "        else:\n",
    "            distances.append([dist,i+1,class_negative])\n",
    "\n",
    "    del distances[pattern_index] #delete the list of distance from the test pattern to itself       \n",
    "\n",
    "    kNN=k\n",
    "    sorted_dist = sorted(distances, key=lambda x: x[0])[:kNN]\n",
    "    #print(sorted_dist)\n",
    "    #create the table of the top 3 min sorted distances\n",
    "\n",
    "    # create the table headers\n",
    "    headers = ['Distancia', 'Patr贸n', 'Clase del patr贸n']\n",
    "\n",
    "    table_latex = tabulate(sorted_dist, headers,floatfmt=\".4f\", tablefmt='latex')\n",
    "\n",
    "    # print(f\"\\n\\item Patr贸n {pattern_index+1}. Ver tabla \\\\ref{{fig{pattern_index+1}}} \\n\")\n",
    "    # print(\"\\\\begin{table}\")\n",
    "    # print(\"\\centering\")\n",
    "    # print(table_latex)\n",
    "    # print(f\"\\caption{{Tabla para el patr贸n {pattern_index+1} (NUTT Dataset)}}\")\n",
    "    # print(f\"\\label{{fig{pattern_index+1}}}\")\n",
    "    # print(\"\\\\end{table}\")\n",
    "\n",
    "\n",
    "    #now i want to count the most repeated class from the KNN list\n",
    "\n",
    "    # extract the third element from each sublist and put them in a separate list\n",
    "    third_elements = [sublist[2] for sublist in sorted_dist]\n",
    "\n",
    "    # use Counter to count the frequency of each value in the third_elements list\n",
    "    counter = Counter(third_elements)\n",
    "\n",
    "    most_common_class = counter.most_common(1)[0][0] #this print the most common class\n",
    "\n",
    "    #print(f\"\\nLa clase que le asgina el clasificador: {most_common_class}\")\n",
    "    \n",
    "    if most_common_class == class_of_test_pattern:\n",
    "        \n",
    "        #print(\"\\nFue un \\\\textbf{ACIERTO}\")\n",
    "        \n",
    "        if class_of_test_pattern==class_positive:\n",
    "            TP +=1\n",
    "        elif class_of_test_pattern==class_negative:\n",
    "            TN +=1\n",
    "    else:\n",
    "        #print(\"\\nFue un \\\\textbf{ERROR}\")\n",
    "\n",
    "        if class_of_test_pattern==class_positive:\n",
    "            FN +=1\n",
    "        elif class_of_test_pattern==class_negative:\n",
    "            FP +=1\n",
    "    return TP,FN,FP,TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d370bc9-cf9b-4fab-b02b-efd6364a6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_positive=0\n",
    "class_negative=1\n",
    "\n",
    "TP=0\n",
    "FN=0\n",
    "FP=0\n",
    "TN=0\n",
    "\n",
    "for i in range(len(df_validation)):\n",
    "    TP,FN,FP,TN=knn_LOOCV(3,df_validation,0,1,i,n,TP,FN,FP,TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afcaf6e-4b83-4fe0-ae16-a58cb292f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 9], [0, 14]]\n"
     ]
    }
   ],
   "source": [
    "CM=[[TP,FN],[FP,TN]]\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6fdbdcf-76a1-4c31-9e88-e7d5a4ba1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medidas(CM):\n",
    "    accuracy = (CM[0][0]+CM[1][1])/(sum(CM[0])+sum(CM[1]))\n",
    "    recall = (CM[0][0]) / (sum(CM[0]))\n",
    "    specificity = (CM[1][1])/sum(CM[1])\n",
    "    balanced_acc= (recall+specificity)/2\n",
    "    \n",
    "    print(f\"\\\\item Accuracy: ${round(accuracy,4)}$\\n\\\\item Recall: ${round(recall,4)}$\\n \\\\item Specificity: ${round(specificity,4)}$\\n \\\\item Balanced Accuracy: ${round(balanced_acc,4)}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6326da41-f9e5-469a-a6d1-acd359f19f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\item Accuracy: $0.68$\n",
      "\\item Recall: $0.36$\n",
      " \\item Specificity: $1.0$\n",
      " \\item Balanced Accuracy: $0.68$\n"
     ]
    }
   ],
   "source": [
    "medidas(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7407e6b-61e3-4d9e-9063-f25cd6ba6cd5",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0ebcd-46d3-42cb-b1c4-569098fc7066",
   "metadata": {},
   "source": [
    "### Parte 2 ELECTRICITY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14a17e8-5afd-41a2-97e2-2814b700d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#path of the file\n",
    "p= \"D:\\\\CIC\\\\CIP\\\\data_sets\\\\Electricity\\\\Electricity.csv\"\n",
    "with open(p, newline='') as csvfile:\n",
    "    \n",
    "    # create a CSV reader object\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # create a list to hold the rows of the CSV file\n",
    "    elec_df = []\n",
    "    \n",
    "    # loop through each row in the CSV file\n",
    "    for row in csvreader:\n",
    "        \n",
    "        # convert the row to a list of numbers\n",
    "        num_row = [float(x) for x in row]\n",
    "        \n",
    "        # add the num_row to the list of rows\n",
    "        elec_df.append(num_row)\n",
    "        \n",
    "# print the 2D list\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf0adbe-88a7-45a3-be38-89f09413b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_dataset(lst):\n",
    "    df=pd.DataFrame(lst)\n",
    "    # Remove columns where all entries are the same\n",
    "    df = df.loc[:, (df != df.iloc[0]).any()]\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remove rows with duplicate values in all but the last column\n",
    "    df_without_last = df.iloc[:, :-1]\n",
    "    df.drop_duplicates(subset=df_without_last.columns.tolist(), inplace=True, keep=False)\n",
    "\n",
    "    arr = df.values.tolist()\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93517f8b-93ee-4e8e-a287-12e617657538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=process_dataset(elec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a2653a0-a034-4af3-bcbd-1845379bce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_df(df,class_1,class_2):\n",
    "    n= len(df[0])-1 #suppose the class column is the last element in the vector\n",
    "    \n",
    "    counter_1 = 0\n",
    "    counter_2 = 0\n",
    "    \n",
    "    for x in df:\n",
    "        if x[n] == class_1:\n",
    "            counter_1 += 1\n",
    "        else:\n",
    "            counter_2 += 1\n",
    "    \n",
    "    if max(counter_1,counter_2)/min(counter_1,counter_2)>1.5:\n",
    "        print(f'Desbalanced Data Set: {max(counter_1,counter_2)}/{min(counter_1,counter_2)}={max(counter_1,counter_2)/min(counter_1,counter_2)}')\n",
    "        if max(counter_1,counter_2)==counter_1:\n",
    "            print(f\"The bigger class is the: {class_1}\")\n",
    "        else:\n",
    "            print(f\"The bigger class is the: {class_2}\")\n",
    "    else:\n",
    "        print(f'Balanced Data Set: {max(counter_1,counter_2)}/{min(counter_1,counter_2)}={max(counter_1,counter_2)/min(counter_1,counter_2)}')\n",
    "        if max(counter_1,counter_2)==counter_1:\n",
    "            print(f\"The bigger class is the: {class_1}\")\n",
    "        else:\n",
    "            print(f\"The bigger class is the: {class_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d073c31-dacb-429c-8fa3-65250483957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Data Set: 1430/970=1.4742268041237114\n",
      "The bigger class is the: 1\n"
     ]
    }
   ],
   "source": [
    "balanced_df(df2,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99cf6091-cd6d-4a12-bd9b-a6505506ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos2,df_neg2 = pos_and_neg(df2,1,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1fd2b4-f973-4842-be99-53718c995a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation2= df_pos2+df_neg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6963e2-7668-400d-978d-e08ab7a63382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_validation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bba7097-1758-41a3-8c01-c3407eec12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last index for the first class (positive) rows in df_validation\n",
    "n_electricity= len(df_pos2)-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62391ac5-5c01-4cc5-a2c3-54fa400c54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_e=0\n",
    "FN_e=0\n",
    "FP_e=0\n",
    "TN_e=0\n",
    "\n",
    "for i in range(len(df_validation2)):\n",
    "    TP_e,FN_e,FP_e,TN_e=knn_LOOCV(11,df_validation2,1,2,i,n_electricity,TP_e,FN_e,FP_e,TN_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f06f824e-a19c-42a1-9e50-0301a62a5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1257, 173], [279, 691]]\n"
     ]
    }
   ],
   "source": [
    "CM_e_1nn=[[TP_e,FN_e],[FP_e,TN_e]]\n",
    "print(CM_e_1nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0a0c183-c48f-4d0b-abea-138da531afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\item Accuracy: $0.8117$\n",
      "\\item Recall: $0.879$\n",
      " \\item Specificity: $0.7124$\n",
      " \\item Balanced Accuracy: $0.7957$\n"
     ]
    }
   ],
   "source": [
    "medidas(CM_e_1nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94664a4-bf53-494b-99d2-187d76781758",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2514eab-6737-4f57-b947-836ea39f935c",
   "metadata": {},
   "source": [
    "# Parte 3 (Clasificador Euclidiano)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb65d6e-2b65-4d75-a0a6-9ade5f20119c",
   "metadata": {},
   "source": [
    "Apply euclidian classifier to the electricity dataset and leave one out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56b4ed24-303e-4722-8771-a3fb9de95a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(lst, n):\n",
    "    \"\"\"Calculate the centroid of the lists in lst, excluding the nth sublist.\"\"\"\n",
    "    sublists = [sublist for i, sublist in enumerate(lst) if i != n]\n",
    "    num_sublists = len(sublists)\n",
    "    if num_sublists == 0:\n",
    "        return None\n",
    "    num_elements = len(sublists[0])\n",
    "    centroid_lst = [0] * num_elements\n",
    "    for i in range(num_elements):\n",
    "        for j in range(num_sublists):\n",
    "            centroid_lst[i] += sublists[j][i]\n",
    "        centroid_lst[i] /= num_sublists\n",
    "    return centroid_lst\n",
    "\n",
    "def centroid_full(points):\n",
    "    n = len(points)\n",
    "    m = len(points[0])\n",
    "    centroid = [0] * m\n",
    "\n",
    "    for point in points:\n",
    "        for i in range(m):\n",
    "            centroid[i] += point[i]\n",
    "\n",
    "    for i in range(m):\n",
    "        centroid[i] /= n\n",
    "\n",
    "    return centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1082923b-8e5a-4c46-ae9f-88c4580402cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_classify(pattern,centroid_pos,centroid_neg,positive_class,negative_class,original_class,TP,FN,FP,TN):\n",
    "    dist_centroid_pos = round(math.dist(pattern, centroid_pos),4)\n",
    "    dist_centroid_neg = round(math.dist(pattern, centroid_neg),4)\n",
    "    \n",
    "    dist_min = min (dist_centroid_pos,dist_centroid_neg)\n",
    "    \n",
    "    if dist_min == dist_centroid_pos:\n",
    "        if original_class == positive_class:\n",
    "            TP +=1\n",
    "        else:\n",
    "            FP +=1\n",
    "    else:\n",
    "        if original_class == negative_class:\n",
    "            TN +=1\n",
    "        else:\n",
    "            FN +=1\n",
    "    \n",
    "    return TP,FN,FP,TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "299ffce4-094f-4377-aed2-fb7201c0cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_e=0\n",
    "FN_e=0\n",
    "FP_e=0\n",
    "TN_e=0\n",
    "\n",
    "for i in range(len(df_validation2)):\n",
    "    if i<= n_electricity:\n",
    "        \n",
    "        original_class=1\n",
    "        pos_controid = centroid(df_pos2,i)\n",
    "        \n",
    "        \n",
    "        neg_centroid = centroid_full(df_neg2)\n",
    "        \n",
    "    else:\n",
    "        original_class=2\n",
    "        pos_controid = centroid_full(df_pos2)\n",
    "        \n",
    "        neg_centroid = centroid(df_neg2,i-n_electricity-1)\n",
    "        \n",
    "    pattern= df_validation2[i]\n",
    "    \n",
    "    TP_e,FN_e,FP_e,TN_e=euclidian_classify(pattern,pos_controid,neg_centroid,1,2,original_class,TP_e,FN_e,FP_e,TN_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d64ab371-c8e2-4745-888d-338a038ebb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[729, 701], [480, 490]]\n"
     ]
    }
   ],
   "source": [
    "CM_euclidian=[[TP_e,FN_e],[FP_e,TN_e]]\n",
    "print(CM_euclidian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71f010cd-2ed2-4c72-8ef2-f1196db518d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\item Accuracy: $0.5079$\n",
      "\\item Recall: $0.5098$\n",
      " \\item Specificity: $0.5052$\n",
      " \\item Balanced Accuracy: $0.5075$\n"
     ]
    }
   ],
   "source": [
    "medidas(CM_euclidian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d6f33-a981-435e-b6a1-b06df50f28ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
